<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">On machine learning model interpretability</h1><p class="page-description">Curated list of resources for data, science, and navigating life</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-05T00:00:00-06:00" itemprop="datePublished">
        Dec 5, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog_fastpages/categories/#exploratory-data-analysis">exploratory-data-analysis</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog_fastpages/categories/#machine-learning">machine-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog_fastpages/categories/#resources">resources</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog_fastpages/categories/#chemical-science">chemical-science</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#future-reading--additional-links">Future Reading / Additional Links</a></li>
<li class="toc-entry toc-h2"><a href="#few-key-work-horses">Few key work horses:</a>
<ul>
<li class="toc-entry toc-h3"><a href="#1-shap">1. SHAP</a></li>
<li class="toc-entry toc-h3"><a href="#2-counterfactuals">2. Counterfactuals</a></li>
<li class="toc-entry toc-h3"><a href="#3-canonical-correlation-analysis">3. Canonical Correlation Analysis</a></li>
</ul>
</li>
</ul><p>Process mindset vs outcome mindset argument – understanding right decision and right outcomes.</p>

<p>Helpful <a href="https://patwalters.github.io/practicalcheminformatics/jupyter/ml/interpretability/2021/06/03/interpretable.html">notebook</a> on simple and useful tips on model interpretations in chemical science from ever-amazing Patrick Walters.</p>

<h2 id="future-reading--additional-links">
<a class="anchor" href="#future-reading--additional-links" aria-hidden="true"><span class="octicon octicon-link"></span></a>Future Reading / Additional Links</h2>

<ul>
  <li>Online Jupyter book on Interpretable Machine Learning(https://christophm.github.io/interpretable-ml-book/index.html) – <strong>highly recommended</strong>
</li>
</ul>

<p>Fantastic book commenting on the mathematics and idea for different method for ML model interpretatability.</p>

<ul>
  <li>
    <p><a href="https://ex.pegg.io/Explainable-AI-cheat-sheet-v0.2.1080.png">Explainable AI Cheetsheet</a>. <a href="https://www.youtube.com/watch?v=Yg3q5x7yDeM">Video</a> discussion on the general idea by Jay Alammar.</p>
  </li>
  <li>
    <p><a href="https://thegradient.pub/interpretability-in-ml-a-broad-overview/">Gradient Blog Commentary on ML interpretability</a></p>
  </li>
  <li>
    <p><a href="https://distill.pub/2020/circuits/zoom-in/">Zoom in on circuits of a Neural Network</a></p>
  </li>
  <li>
    <p><a href="https://neptune.ai/blog/explainability-auditability-ml-definitions-techniques-tools">Neptune Blog article on interpretable models</a></p>
  </li>
  <li>
    <p><a href="https://github.com/pytorch/captum">Module for incorporating model interpretatbility for PyTorch models</a></p>
  </li>
</ul>

<h2 id="few-key-work-horses">
<a class="anchor" href="#few-key-work-horses" aria-hidden="true"><span class="octicon octicon-link"></span></a>Few key work horses:</h2>

<h3 id="1-shap">
<a class="anchor" href="#1-shap" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. SHAP</h3>

<p>SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model.<a href="https://github.com/slundberg/shap">Github</a></p>

<p>Considering cooperative prediction - the value added by the feature contribution to the final output and compare it to its individual output if that feature was active.</p>

<p>Given the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.</p>

<h3 id="2-counterfactuals">
<a class="anchor" href="#2-counterfactuals" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Counterfactuals</h3>

<blockquote>
  <p>If X had not occured, would have Y occured?</p>
</blockquote>

<p>A counterfactual is a idea of relating an action to a consequence.</p>

<p>“Would I have got a cold, if I had not eaten the ice-cream?”</p>

<p>Usually a model agnostic approach is implemented, wherein the input(s) of the model is varied and its effect on the prediction is analyzed. Mind here  that we dont really care <strong>how</strong> the model predicts tthe output but <strong>just</strong> if the output changes by changing the input.</p>

<p>The idea echoes with the concept of <a href="https://pubs.acs.org/doi/10.1021/acscatal.7b00115"><strong>degree of rate control</strong></a> first proposed by Charles Campbell to propose kinetic pathways and intermediates which have most impact on the final chemical reaction rate.</p>

<p>Counterfactual have an important drawback - they suffer from the possibility of multiple truths. 
Explain on why that molecule: Andrew White Lab.
<a href="https://ur-whitelab.github.io/exmol/">Github</a></p>

<p><a href="https://iwatobipen.wordpress.com/2021/09/18/try-to-use-exmol-to-explain-why-the-model-predicts-it-chemoinfomratics-rdkit-exmol/?utm_source=pocket_mylist">Pen’s blog on implementation of Exmol</a></p>

<p><a href="https://towardsdatascience.com/understanding-machine-learning-models-better-with-explainable-ai-bea6d28f5094">ExplainerDashboard python package</a></p>

<p><a href="https://arxiv.org/abs/1802.03268">Automate model design and NN architecture search?</a></p>

<h3 id="3-canonical-correlation-analysis">
<a class="anchor" href="#3-canonical-correlation-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Canonical Correlation Analysis</h3>

<p><a href="https://www.youtube.com/watch?v=u7Dvb_a1D-0">Video</a> from Jay Alammar.</p>

  </div><a class="u-url" href="/blog_fastpages/exploratory-data-analysis/machine-learning/resources/chemical-science/2021/12/05/ML_interpretability.html" hidden></a>
</article>