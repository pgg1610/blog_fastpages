{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-scraping Hindi (Bollywood) movies from IMDb\n",
    "\n",
    "Using `BeautifulSoup` to scrap IMDb movie data-base by querying for Bollywood movies. The data-base is then used to analyze trends over time.\n",
    "* Pandas aggregation link : [Here](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import time as time \n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.core.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, year, imdb_rating, metascore, num_votes = [], [], [], [], [] \n",
    "\n",
    "start_time = time.time()\n",
    "requests = 0\n",
    "\n",
    "years_url = [str(i) for i in range(2006,2021)]\n",
    "page_iter = [0, 51, 101, 151, 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:23<00:00,  4.76s/it]\u001b[A\n",
      "100%|██████████| 15/15 [05:48<00:00, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dataframe for year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year_url in tqdm(years_url):\n",
    "    for page_num in tqdm(page_iter):\n",
    "        #URL to parse \n",
    "        url = 'https://www.imdb.com/search/title/?title_type=feature,&release_date={0},{0}&countries=in&languages=hi&sort=num_votes,desc&start={1}&ref_=adv_prv'.format(int(year_url), int(page_num))\n",
    "        response = get(url)\n",
    "        \n",
    "        #Sleep to carve out load \n",
    "        time.sleep(np.random.randint(1,5))\n",
    "        \n",
    "        #Estimate time elapsed per request\n",
    "        requests += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        movie_containers = html_soup.find_all('div', class_='lister-item mode-advanced')\n",
    "        \n",
    "        for i, container in enumerate(movie_containers):\n",
    "            container_entry = movie_containers[i] \n",
    "            movie_name = container_entry.h3.a.text\n",
    "            names.append(movie_name)\n",
    "            \n",
    "            movie_year = container_entry.h3.find('span',class_='lister-item-year text-muted unbold').text.strip('()')\n",
    "            year.append(movie_year)\n",
    "            #print(movie_name, movie_year)\n",
    "            \n",
    "            try:\n",
    "                movie_rating = float(container_entry.strong.text)\n",
    "                imdb_rating.append(movie_rating)\n",
    "            except AttributeError:\n",
    "                imdb_rating.append(np.nan)\n",
    "            \n",
    "            try:\n",
    "                movie_votes = float(''.join(container_entry.find('span', attrs = {'name':'nv'}).text.split(',')))\n",
    "                num_votes.append(movie_votes)\n",
    "            except (AttributeError, ValueError):\n",
    "                num_votes.append(np.nan)\n",
    "                \n",
    "            try:\n",
    "                movie_metascore = float(container_entry.find('span', class_='metascore').text.strip())\n",
    "                metascore.append(movie_metascore)\n",
    "            except AttributeError:\n",
    "                metascore.append(np.nan)\n",
    "    \n",
    "    print('Making dataframe for year {}'.format(year_url))\n",
    "    df_movies = pd.DataFrame({'name':names,'year':year,'rating':imdb_rating,'metascore':metascore,'num_votes':num_votes})\n",
    "    df_movies.to_csv('./temp_imdb_files/bollywood_data_{}.csv'.format(year_url),sep=',',header=True, index=False)\n",
    "    del df_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./temp_imdb_files/bollywood_data_2005.csv',sep=',')\n",
    "df2 = pd.read_csv('./temp_imdb_files/bollywood_data_2020.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat((df1, df2)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('./bollywood_movies_data_1950_2020.csv',sep=',',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
